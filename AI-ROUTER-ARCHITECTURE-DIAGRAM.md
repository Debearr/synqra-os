# AI Router - Architecture Diagram

## System Overview

```
┌─────────────────────────────────────────────────────────────────┐
│                        INPUT LAYER                              │
│  ┌──────────┐  ┌──────────┐  ┌──────────┐  ┌──────────┐       │
│  │   API    │  │  Agents  │  │Templates │  │ Direct   │       │
│  │  Route   │  │  System  │  │  System  │  │   Call   │       │
│  └────┬─────┘  └────┬─────┘  └────┬─────┘  └────┬─────┘       │
│       └─────────────┴─────────────┴─────────────┘              │
└───────────────────────────┬─────────────────────────────────────┘
                            │
                            ▼
┌─────────────────────────────────────────────────────────────────┐
│                    PREPROCESSING LAYER                          │
│  ┌────────────────────────────────────────────────────────┐    │
│  │  1. Cache Check                                        │    │
│  │     └─ Hit? → Return cached response (COST: $0)       │    │
│  │     └─ Miss? → Continue pipeline                      │    │
│  └────────────────────────────────────────────────────────┘    │
│  ┌────────────────────────────────────────────────────────┐    │
│  │  2. Input Compression (if > 500 chars)                │    │
│  │     └─ Target: 50-150 tokens                          │    │
│  │     └─ Remove filler, extract key sentences           │    │
│  └────────────────────────────────────────────────────────┘    │
│  ┌────────────────────────────────────────────────────────┐    │
│  │  3. Context Reduction                                  │    │
│  │     └─ Keep most recent history (max 1000 chars)      │    │
│  └────────────────────────────────────────────────────────┘    │
└───────────────────────────┬─────────────────────────────────────┘
                            │
                            ▼
┌─────────────────────────────────────────────────────────────────┐
│                    COMPLEXITY SCORING                           │
│  ┌────────────────────────────────────────────────────────┐    │
│  │  Analyze:                                              │    │
│  │  • Length (0-0.5)                                      │    │
│  │  • Structure required? (+0.2)                         │    │
│  │  • Reasoning depth? (+0.3)                            │    │
│  │  • Client-facing? (+0.15)                             │    │
│  │                                                        │    │
│  │  Score → 0.0 to 1.0                                   │    │
│  └────────────────────────────────────────────────────────┘    │
└───────────────────────────┬─────────────────────────────────────┘
                            │
                            ▼
┌─────────────────────────────────────────────────────────────────┐
│                    MODEL SELECTION                              │
│  ┌────────────────────────────────────────────────────────┐    │
│  │  IF final_deliverable = true                          │    │
│  │     → GPT-5 (1500 tokens max)                         │    │
│  │                                                        │    │
│  │  ELSE IF score > 0.85 AND client_facing               │    │
│  │     → Claude (1200 tokens max)                        │    │
│  │                                                        │    │
│  │  ELSE IF score >= 0.8                                 │    │
│  │     → DeepSeek (600 tokens max)                       │    │
│  │                                                        │    │
│  │  ELSE IF score >= 0.5                                 │    │
│  │     → Mistral + DeepSeek validation (350+600)         │    │
│  │                                                        │    │
│  │  ELSE (score < 0.5)                                   │    │
│  │     → Mistral (350 tokens max)                        │    │
│  └────────────────────────────────────────────────────────┘    │
└───────────────────────────┬─────────────────────────────────────┘
                            │
                            ▼
┌─────────────────────────────────────────────────────────────────┐
│                    COST ESTIMATION                              │
│  ┌────────────────────────────────────────────────────────┐    │
│  │  Calculate:                                            │    │
│  │  • Input tokens (length / 4)                          │    │
│  │  • Output tokens (budget * 0.3)                       │    │
│  │  • Cost = tokens × model_rate                         │    │
│  │                                                        │    │
│  │  IF cost > max_budget                                 │    │
│  │     → Downgrade model                                 │    │
│  │     → Recalculate                                     │    │
│  └────────────────────────────────────────────────────────┘    │
└───────────────────────────┬─────────────────────────────────────┘
                            │
                            ▼
┌─────────────────────────────────────────────────────────────────┐
│                    EXECUTION PIPELINE                           │
│  ┌────────────────────────────────────────────────────────┐    │
│  │  Step 1: Mistral Extract (if not Mistral-only)       │    │
│  │     └─ Extract key information                        │    │
│  │     └─ Cost: ~$0.0001                                 │    │
│  └────────────────────────────────────────────────────────┘    │
│                            │                                    │
│  ┌────────────────────────────────────────────────────────┐    │
│  │  Step 2: DeepSeek Compress (if score >= 0.5)         │    │
│  │     └─ Compress + validate                            │    │
│  │     └─ Cost: ~$0.0002                                 │    │
│  └────────────────────────────────────────────────────────┘    │
│                            │                                    │
│  ┌────────────────────────────────────────────────────────┐    │
│  │  Step 3: Model Execute                                │    │
│  │     ├─ Mistral: $0.0001-0.0003                        │    │
│  │     ├─ DeepSeek: $0.0002-0.0005                       │    │
│  │     ├─ Claude: $0.005-0.015                           │    │
│  │     └─ GPT-5: $0.020-0.040                            │    │
│  └────────────────────────────────────────────────────────┘    │
│                            │                                    │
│  ┌────────────────────────────────────────────────────────┐    │
│  │  Step 4: DeepSeek Validate (if score >= 0.8)         │    │
│  │     └─ Quality check                                  │    │
│  │     └─ Cost: ~$0.0001                                 │    │
│  └────────────────────────────────────────────────────────┘    │
└───────────────────────────┬─────────────────────────────────────┘
                            │
                            ▼
┌─────────────────────────────────────────────────────────────────┐
│                    POSTPROCESSING LAYER                         │
│  ┌────────────────────────────────────────────────────────┐    │
│  │  1. Cache Response                                     │    │
│  │     └─ Store: response + model + timestamp            │    │
│  │     └─ TTL: 24 hours                                  │    │
│  └────────────────────────────────────────────────────────┘    │
│  ┌────────────────────────────────────────────────────────┐    │
│  │  2. Log Usage to Supabase                             │    │
│  │     └─ task_id, model, tokens, costs, complexity      │    │
│  └────────────────────────────────────────────────────────┘    │
│  ┌────────────────────────────────────────────────────────┐    │
│  │  3. Return Response                                    │    │
│  │     └─ Include: answer + metadata + cost              │    │
│  └────────────────────────────────────────────────────────┘    │
└───────────────────────────┬─────────────────────────────────────┘
                            │
                            ▼
                     [CLIENT RESPONSE]
```

## Model Hierarchy

```
┌─────────────────────────────────────────────────────────┐
│                  MODEL SELECTION TREE                   │
└─────────────────────────────────────────────────────────┘

                        [Task Input]
                             │
                             ▼
                    ┌────────────────┐
                    │ Complexity     │
                    │ Score: 0-1     │
                    └────────┬───────┘
                             │
            ┌────────────────┼────────────────┐
            │                │                │
            ▼                ▼                ▼
      [0.0-0.4]         [0.5-0.7]       [0.8-1.0]
      Simple           Moderate         Complex
            │                │                │
            ▼                ▼                ▼
     ┌──────────┐    ┌──────────┐    ┌──────────┐
     │ MISTRAL  │    │ MISTRAL  │    │ DeepSeek │
     │ 350 tok  │    │    +     │    │ 600 tok  │
     │ $0.0001  │    │ DeepSeek │    │ $0.0003  │
     └──────────┘    │ 950 tok  │    └──────────┘
                     │ $0.0003  │           │
                     └──────────┘           │
                                            │
                                ┌───────────┴────────────┐
                                │                        │
                          Client-facing?              Not
                                │                    client
                                ▼                    facing
                         ┌──────────┐                   │
                         │  CLAUDE  │                   │
                         │ 1200 tok │                   │
                         │ $0.0105  │                   │
                         └──────────┘                   │
                                                        │
                                            Final deliverable?
                                                        │
                                                        ▼
                                                 ┌──────────┐
                                                 │  GPT-5   │
                                                 │ 1500 tok │
                                                 │ $0.0360  │
                                                 └──────────┘
```

## Cost Flow

```
┌─────────────────────────────────────────────────────────────┐
│                     COST BREAKDOWN                          │
└─────────────────────────────────────────────────────────────┘

100 Tasks/Day Distribution:

┌──────────────────┐
│ 70% Simple       │  →  Mistral Only
│ (70 tasks)       │      $0.0001/task
│                  │      Daily: $0.007
└──────────────────┘

┌──────────────────┐
│ 20% Moderate     │  →  Mistral + DeepSeek
│ (20 tasks)       │      $0.0003/task
│                  │      Daily: $0.006
└──────────────────┘

┌──────────────────┐
│ 8% Complex       │  →  Full Pipeline → Claude
│ (8 tasks)        │      $0.0105/task
│                  │      Daily: $0.084
└──────────────────┘

┌──────────────────┐
│ 2% Final         │  →  Full Pipeline → GPT-5
│ (2 tasks)        │      $0.0360/task
│                  │      Daily: $0.072
└──────────────────┘

Total Daily:  $0.169
Total Monthly: $5.07
Total Annual:  $60.84

Savings vs All-Claude ($378/year): $317.16 (84%)
```

## Cache Architecture

```
┌─────────────────────────────────────────────────────────────┐
│                    CACHE FLOW                               │
└─────────────────────────────────────────────────────────────┘

Request
   │
   ▼
┌──────────────┐
│ Generate Key │  (input + system_prompt → hash)
└──────┬───────┘
       │
       ▼
┌──────────────┐
│  Check Cache │
└──────┬───────┘
       │
       ├─ Hit  → Return cached (Cost: $0)
       │         Log: cache_hit = true
       │
       └─ Miss → Continue pipeline
                 Execute model
                 Store in cache (TTL: 24h)
                 Log: cache_hit = false

Cache Stats:
• Hit Rate: 25% target
• Savings: $0.25 per hit
• Monthly: ~750 hits × $0.0105 = $7.88 saved
```

## Data Flow

```
┌─────────────────────────────────────────────────────────────┐
│                    DATA FLOW                                │
└─────────────────────────────────────────────────────────────┘

┌──────────────────────────────────────────────────────────────┐
│                        SUPABASE                              │
│  ┌────────────────────────────────────────────────────┐     │
│  │          ai_model_usage TABLE                      │     │
│  │                                                     │     │
│  │  Columns:                                          │     │
│  │  • id (UUID)                                       │     │
│  │  • task_id (TEXT)                                  │     │
│  │  • model (TEXT)                                    │     │
│  │  • input_tokens (INTEGER)                          │     │
│  │  • output_tokens (INTEGER)                         │     │
│  │  • estimated_cost (DECIMAL)                        │     │
│  │  • actual_cost (DECIMAL)                           │     │
│  │  • complexity (DECIMAL)                            │     │
│  │  • cache_hit (BOOLEAN)                             │     │
│  │  • created_at (TIMESTAMP)                          │     │
│  │                                                     │     │
│  │  Indexes:                                          │     │
│  │  • created_at (for date range queries)            │     │
│  │  • model (for per-model analysis)                 │     │
│  │  • task_id (for task tracking)                    │     │
│  └────────────────────────────────────────────────────┘     │
└──────────────────────────────────────────────────────────────┘
              │
              │ INSERT after each task
              │
┌─────────────▼─────────────────────────────────────────────────┐
│                    ANALYTICS LAYER                            │
│  ┌────────────────────────────────────────────────────────┐  │
│  │  • Cost tracking                                       │  │
│  │  • Model distribution                                  │  │
│  │  • Cache hit rate                                      │  │
│  │  • Complexity trends                                   │  │
│  │  • Monthly reports                                     │  │
│  └────────────────────────────────────────────────────────┘  │
└───────────────────────────────────────────────────────────────┘
```

## Integration Points

```
┌─────────────────────────────────────────────────────────────┐
│              EXISTING SYSTEM INTEGRATION                    │
└─────────────────────────────────────────────────────────────┘

┌──────────────────────┐         ┌──────────────────────┐
│   BaseAgent          │         │   AI Router          │
│   (Existing)         │◄────────┤   (New)              │
│                      │ Wrapped │                      │
│  • Sales Agent       │   by    │  • Model Selection   │
│  • Support Agent     │         │  • Cost Optimization │
│  • Service Agent     │         │  • Caching           │
└──────────────────────┘         └──────────────────────┘
         │                                  │
         │                                  │
         ▼                                  ▼
┌──────────────────────┐         ┌──────────────────────┐
│   Claude API         │         │  Multi-Model API     │
│   (Fallback)         │         │  • Mistral           │
│                      │         │  • DeepSeek          │
│                      │         │  • Claude            │
│                      │         │  • GPT-5             │
└──────────────────────┘         └──────────────────────┘

Integration Methods:
1. wrapAgent() - Wraps existing agents
2. executeTask() - Direct task execution
3. generateFromTemplate() - Template-based
4. batchProcess() - Batch operations
```

---

**Self-Check Complete — Output Verified.**
