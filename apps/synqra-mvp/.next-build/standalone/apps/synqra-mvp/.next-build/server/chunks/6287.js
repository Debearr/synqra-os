exports.id=6287,exports.ids=[6287],exports.modules={7032:()=>{},408:()=>{},9109:(e,a,n)=>{"use strict";n.d(a,{$v:()=>l,JK:()=>d,getLoaderStatus:()=>g});var o=n(4226);let t={loadedModels:new Set,loadingModels:new Set,failedModels:new Set,modelInstances:new Map,lastUsed:new Map};async function l(){console.log("\uD83E\uDD16 Initializing local model system...");let e=(0,o.Mg)(),a={success:!0,loaded:[],failed:[]};for(let n of e)try{console.log(`   Loading ${n.name}...`),await c(n.id),a.loaded.push(n.id),console.log(`   âœ… ${n.name} loaded`)}catch(e){console.error(`   âŒ Failed to load ${n.name}:`,e),a.failed.push(n.id),a.success=!1}return console.log(`ðŸ¤– Model initialization complete:`),console.log(`   Loaded: ${a.loaded.length}`),console.log(`   Failed: ${a.failed.length}`),a}async function c(e){if(t.loadedModels.has(e)){console.log(`   â„¹ï¸  Model ${e} already loaded`);return}if(t.loadingModels.has(e)){for(console.log(`   â³ Model ${e} is currently loading...`);t.loadingModels.has(e);)await new Promise(e=>setTimeout(e,100));return}if(t.failedModels.has(e))throw Error(`Model ${e} previously failed to load`);let a=(0,o.Ac)(e);if(!a)throw Error(`Model ${e} not found in registry`);t.loadingModels.add(e);try{switch(a.backend){case"onnx":await i(a);break;case"python-service":await s(a);break;case"api":break;default:throw Error(`Unsupported backend: ${a.backend}`)}t.loadedModels.add(e),t.lastUsed.set(e,Date.now()),console.log(`âœ… Model ${e} loaded successfully`)}catch(a){throw t.failedModels.add(e),a}finally{t.loadingModels.delete(e)}}async function i(e){console.log(`   ðŸ“¦ Loading ONNX model: ${e.huggingFaceId}`),t.modelInstances.set(e.id,{type:"onnx",config:e,placeholder:!0}),await new Promise(e=>setTimeout(e,100))}async function s(e){console.log(`   ðŸ Connecting to Python service for: ${e.huggingFaceId}`);let a=process.env.PYTHON_MODEL_SERVICE_URL||"http://localhost:8000";try{let n=await fetch(`${a}/health`,{method:"GET",signal:AbortSignal.timeout(5e3)});if(!n.ok)throw Error(`Python service not healthy: ${n.status}`);let o=await fetch(`${a}/models/load`,{method:"POST",headers:{"Content-Type":"application/json"},body:JSON.stringify({modelId:e.id,huggingFaceId:e.huggingFaceId,modelType:e.type}),signal:AbortSignal.timeout(3e4)});if(!o.ok)throw Error(`Failed to register model: ${o.status}`);t.modelInstances.set(e.id,{type:"python-service",serviceUrl:a,config:e}),console.log(`   âœ… Python service model registered: ${e.id}`)}catch(a){console.warn(`   âš ï¸  Python service not available for ${e.id}, using fallback`),t.modelInstances.set(e.id,{type:"python-service",config:e,fallback:!0})}}async function d(e){let a=Date.now(),n=(0,o.Ac)(e.modelId);if(!n)throw Error(`Model ${e.modelId} not found`);if(!t.loadedModels.has(e.modelId)){if(n.lazyLoad)await c(e.modelId);else throw Error(`Model ${e.modelId} not loaded`)}t.lastUsed.set(e.modelId,Date.now());try{let o;switch(n.backend){case"onnx":o=await r(e,n);break;case"python-service":o=await m(e,n);break;case"api":o=await u(e,n);break;default:throw Error(`Unsupported backend: ${n.backend}`)}let t=Date.now()-a;return{modelId:e.modelId,output:o,confidence:.85,latencyMs:t,cost:n.costPerInference,cached:!1,timestamp:Date.now()}}catch(a){throw console.error(`Inference failed for ${e.modelId}:`,a),a}}async function r(e,a){let n=t.modelInstances.get(e.modelId);return(!n||n.placeholder)&&console.warn(`âš ï¸  ONNX inference not implemented, using mock for ${e.modelId}`),p(e,a)}async function m(e,a){let n=t.modelInstances.get(e.modelId);if(!n||n.fallback)return console.warn(`âš ï¸  Python service not available, using fallback for ${e.modelId}`),p(e,a);let{serviceUrl:o}=n;try{let n=await fetch(`${o}/models/infer`,{method:"POST",headers:{"Content-Type":"application/json"},body:JSON.stringify({modelId:e.modelId,input:e.input,options:e.options}),signal:AbortSignal.timeout(3*a.avgLatencyMs)});if(!n.ok)throw Error(`Inference failed: ${n.status}`);return(await n.json()).output}catch(n){return console.error(`Python service inference failed for ${e.modelId}:`,n),p(e,a)}}async function u(e,a){return a.id.includes("claude"),p(e,a)}function p(e,a){switch(console.warn(`ðŸ”„ Using mock inference for ${a.id}`),a.type){case"embeddings":return Array.from({length:384},()=>Math.random());case"sentiment":return{label:"POSITIVE",score:.85};case"toxicity":return{toxic:!1,score:.05};case"llm":return`Mock response from ${a.name}. Input was: ${String(e.input).substring(0,50)}...`;case"vision":return{embedding:Array.from({length:512},()=>Math.random())};case"ocr":return{text:"Mock OCR text",confidence:.9};case"document":return{parsed:{},text:"Mock document parse"};case"audio":return{text:"Mock audio transcription",confidence:.88};case"reranker":return{score:.75,rank:1};default:return{result:"mock"}}}function g(){let e=Array.from(t.loadedModels),a=e.reduce((e,a)=>{let n=(0,o.Ac)(a);return e+(n?.memoryMB||0)},0);return{loaded:e,loading:Array.from(t.loadingModels),failed:Array.from(t.failedModels),totalMemoryMB:a}}},4226:(e,a,n)=>{"use strict";n.d(a,{Ac:()=>t,Mg:()=>l});let o={"bge-small-en-v1.5":{id:"bge-small-en-v1.5",name:"BGE Small English v1.5",type:"embeddings",size:"small",backend:"onnx",memoryMB:120,cpuIntensive:!1,gpuOptional:!0,preload:!0,lazyLoad:!1,cacheResults:!0,huggingFaceId:"BAAI/bge-small-en-v1.5",localPath:".model_cache/bge-small-en-v1.5",costPerInference:0,avgLatencyMs:15,maxBatchSize:32},"minilm-l6-v2":{id:"minilm-l6-v2",name:"MiniLM L6 v2",type:"embeddings",size:"tiny",backend:"onnx",memoryMB:80,cpuIntensive:!1,gpuOptional:!1,preload:!0,lazyLoad:!1,cacheResults:!0,huggingFaceId:"sentence-transformers/all-MiniLM-L6-v2",localPath:".model_cache/minilm-l6-v2",costPerInference:0,avgLatencyMs:8,maxBatchSize:64},"minilm-l12-v2":{id:"minilm-l12-v2",name:"MiniLM L12 v2 (Reranker)",type:"reranker",size:"small",backend:"onnx",memoryMB:120,cpuIntensive:!1,gpuOptional:!1,preload:!1,lazyLoad:!0,cacheResults:!0,huggingFaceId:"sentence-transformers/all-MiniLM-L12-v2",localPath:".model_cache/minilm-l12-v2",costPerInference:0,avgLatencyMs:12,maxBatchSize:32},"distilbert-sentiment":{id:"distilbert-sentiment",name:"DistilBERT Sentiment",type:"sentiment",size:"small",backend:"onnx",memoryMB:250,cpuIntensive:!1,gpuOptional:!1,preload:!0,lazyLoad:!1,cacheResults:!0,huggingFaceId:"distilbert-base-uncased-finetuned-sst-2-english",localPath:".model_cache/distilbert-sentiment",costPerInference:0,avgLatencyMs:20,maxBatchSize:16},"roberta-toxicity":{id:"roberta-toxicity",name:"RoBERTa Toxicity Detector",type:"toxicity",size:"base",backend:"onnx",memoryMB:300,cpuIntensive:!1,gpuOptional:!1,preload:!0,lazyLoad:!1,cacheResults:!0,huggingFaceId:"unitary/toxic-bert",localPath:".model_cache/roberta-toxicity",costPerInference:0,avgLatencyMs:25,maxBatchSize:16},"llama-3.2-1b":{id:"llama-3.2-1b",name:"Llama 3.2 1B",type:"llm",size:"small",backend:"python-service",memoryMB:2048,cpuIntensive:!0,gpuOptional:!0,preload:!1,lazyLoad:!0,cacheResults:!0,huggingFaceId:"meta-llama/Llama-3.2-1B",localPath:".model_cache/llama-3.2-1b",costPerInference:0,avgLatencyMs:800,maxBatchSize:1},"openclip-vit-b32":{id:"openclip-vit-b32",name:"OpenCLIP ViT-B/32",type:"vision",size:"base",backend:"python-service",memoryMB:600,cpuIntensive:!0,gpuOptional:!0,preload:!1,lazyLoad:!0,cacheResults:!0,huggingFaceId:"laion/CLIP-ViT-B-32-laion2B-s34B-b79K",localPath:".model_cache/openclip-vit-b32",costPerInference:0,avgLatencyMs:150,maxBatchSize:8},"paddle-ocr":{id:"paddle-ocr",name:"PaddleOCR",type:"ocr",size:"small",backend:"python-service",memoryMB:400,cpuIntensive:!0,gpuOptional:!0,preload:!1,lazyLoad:!0,cacheResults:!0,huggingFaceId:"PaddlePaddle/PaddleOCR",localPath:".model_cache/paddle-ocr",costPerInference:0,avgLatencyMs:200,maxBatchSize:4},donut:{id:"donut",name:"Donut Document Understanding",type:"document",size:"base",backend:"python-service",memoryMB:800,cpuIntensive:!0,gpuOptional:!0,preload:!1,lazyLoad:!0,cacheResults:!0,huggingFaceId:"naver-clova-ix/donut-base",localPath:".model_cache/donut",costPerInference:0,avgLatencyMs:400,maxBatchSize:1},"faster-whisper":{id:"faster-whisper",name:"Faster Whisper",type:"audio",size:"base",backend:"python-service",memoryMB:500,cpuIntensive:!0,gpuOptional:!0,preload:!1,lazyLoad:!0,cacheResults:!0,huggingFaceId:"guillaumekln/faster-whisper-base",localPath:".model_cache/faster-whisper",costPerInference:0,avgLatencyMs:1e3,maxBatchSize:1},"claude-3.5-sonnet":{id:"claude-3.5-sonnet",name:"Claude 3.5 Sonnet",type:"llm",size:"large",backend:"api",memoryMB:0,cpuIntensive:!1,gpuOptional:!1,preload:!1,lazyLoad:!1,cacheResults:!1,costPerInference:.015,avgLatencyMs:2e3,maxBatchSize:1},"deepseek-v3":{id:"deepseek-v3",name:"DeepSeek V3",type:"llm",size:"large",backend:"api",memoryMB:0,cpuIntensive:!1,gpuOptional:!1,preload:!1,lazyLoad:!1,cacheResults:!1,costPerInference:.008,avgLatencyMs:1500,maxBatchSize:1},"gpt-4o":{id:"gpt-4o",name:"GPT-4o",type:"llm",size:"large",backend:"api",memoryMB:0,cpuIntensive:!1,gpuOptional:!1,preload:!1,lazyLoad:!1,cacheResults:!1,costPerInference:.02,avgLatencyMs:2500,maxBatchSize:1}};function t(e){return o[e]||null}function l(){return Object.values(o).filter(e=>e.preload)}}};